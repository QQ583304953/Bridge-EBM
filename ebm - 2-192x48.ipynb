{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b076bd1a-b236-4fbc-953d-8295b25122ae",
   "metadata": {},
   "source": [
    "# ⚡️ Energy-Based Models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9235cbd1-f136-411c-88d9-f69f270c0b96",
   "metadata": {},
   "source": [
    "In this notebook, we'll walk through the steps required to train your own Energy Based Model to predict the distribution of a demo dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2531aef5-c81a-4b53-a344-4b979dd4eec5",
   "metadata": {},
   "source": [
    "The code is adapted from the excellent ['Deep Energy-Based Generative Models' tutorial](https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial8/Deep_Energy_Models.html) created by Phillip Lippe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "84acc7be-6764-4668-b2bb-178f63deeed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "startTime=time.time()\n",
    "         \n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import (\n",
    "    datasets,\n",
    "    layers,\n",
    "    models,\n",
    "    optimizers,\n",
    "    activations,\n",
    "    metrics,\n",
    "    callbacks,\n",
    "    utils,\n",
    ")\n",
    "\n",
    "from notebooks.utils import display, sample_batch\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "339e6268-ebd7-4feb-86db-1fe7abccdbe5",
   "metadata": {},
   "source": [
    "## 0. Parameters <a name=\"parameters\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2ee6ce-129f-4833-b0c5-fa567381c4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#调整参数\n",
    "STEP_SIZE = 10 #def generate_samples()梯度下降算法更新图像的学习率（步长）。原值10\n",
    "STEPS = 360 #训练时def generate_samples()梯度下降算法更新图像的循环次数【最终生成结果时是1000】.原值60。影响训练速度的主要参数。\n",
    "ALPHA = 0.2 #正则损失系数。原值0.1.\n",
    "NOISE = 0.005 #图像上增加噪声（设定正态分布标准差）。原值0.005\n",
    "LEARNING_RATE = 0.0001 #原值0.0001\n",
    "\n",
    "GRADIENT_CLIP = 0.03 #def generate_samples()梯度下降算法更新图像的梯度剪裁\n",
    "\n",
    "EPOCHS = 50 #原值60。\n",
    "LOAD_MODEL = False\n",
    "\n",
    "BATCH_SIZE = 128 #查看显存占用比例“nvidia-smi”。\n",
    "BUFFER_SIZE = 8192 #class Buffer()以前迭代的样本缓冲区，保留最大样本数目.原值8192\n",
    "\n",
    "\n",
    "#固定参数\n",
    "train_dir=\".\\\\png 192x48_GRAY\\\\\" #文件名字符数目不能过多，否则出错，故在旋转、缩放、平移变换时减少文件名字符。\n",
    "IMAGE_SIZE =  (48, 192) #再小清晰度就不满足了\n",
    "CHANNELS = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a73e5a4-1638-411c-8d3c-29f823424458",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "train_data = utils.image_dataset_from_directory(\n",
    "    train_dir, \n",
    "    labels=None,\n",
    "    color_mode=\"grayscale\", \n",
    "    image_size=IMAGE_SIZE, \n",
    "    batch_size=BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    seed=41,\n",
    "    interpolation=\"bilinear\", #双线性插值\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea220974-4c72-428f-8357-3e6c75735d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sample = sample_batch(train_data)\n",
    "print(train_sample.shape) \n",
    "np.savetxt('train_sample[0]-1.txt', train_sample[0][:,:,0])  #像素值0~255\n",
    "display(train_sample, n=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13eb5f91-e2f1-4376-873a-38c7b84f2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the data\n",
    "def preprocess(imgs):\n",
    "    imgs = (tf.cast(imgs, \"float32\") - 127.5) / 127.5 ##tf.cast()函数：数据类型转换.放缩到 [-1, 1]\n",
    "    return imgs\n",
    "\n",
    "x_train = train_data.map(lambda x: preprocess(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e1a420-699e-4869-8d10-3c049dbad030",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show some items of clothing from the training set\n",
    "train_sample = sample_batch(x_train)\n",
    "print(train_sample.shape) \n",
    "np.savetxt('train_sample[0]-2.txt', train_sample[0][:,:,0])  #\n",
    "display(train_sample, n=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53945d9-b7c5-49d0-a356-bcf1d1e1798b",
   "metadata": {},
   "source": [
    "## 2. Build the EBM network <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e84945-ed93-4091-964d-a85ec9d5b98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#参考我过去的“VAE、WGAN论文”对神经元数目修改、增加BatchNormalization，层数不作调整，达到VAE解码器参数量。\n",
    "ebm_input = layers.Input(shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "x = layers.Conv2D(32, kernel_size=5, strides=2, padding=\"same\")(ebm_input)\n",
    "x = layers.BatchNormalization()(x) #自己增加\n",
    "x = layers.Activation(activations.swish)(x)\n",
    "#x = layers.Dropout(0.3)(x) #自己增加，必须self.model(inp_imgs, training=True)\n",
    "x = layers.Conv2D(64, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(activations.swish)(x)\n",
    "#x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(activations.swish)(x)\n",
    "#x = layers.Dropout(0.3)(x)\n",
    "x = layers.Conv2D(128, kernel_size=3, strides=2, padding=\"same\")(x)\n",
    "x = layers.BatchNormalization()(x)\n",
    "x = layers.Activation(activations.swish)(x)\n",
    "#x = layers.Dropout(0.3)(x)\n",
    "x = layers.Flatten()(x)\n",
    "x = layers.Dense(128, activation=activations.swish)(x) #取消该层效果差\n",
    "ebm_output = layers.Dense(1)(x)\n",
    "model = models.Model(ebm_input, ebm_output)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32221908-8819-48fa-8e57-0dc5179ca2cf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if LOAD_MODEL:\n",
    "    model.load_weights(\"./models/model.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f392424-45a9-49cc-8ea0-c1bec9064d74",
   "metadata": {},
   "source": [
    "## 2. Set up a Langevin sampler function <a name=\"sampler\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf10775a-0fbf-42df-aca5-be4b256a0c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate samples using Langevin Dynamics\n",
    "def generate_samples(model, inp_imgs, steps, step_size, noise, return_img_per_step=False):\n",
    "    imgs_per_step = []\n",
    "    for _ in range(steps):\n",
    "        inp_imgs += tf.random.normal(inp_imgs.shape, mean=0, stddev=noise) #图像上增加噪声。\n",
    "        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0) #剪裁\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(inp_imgs)\n",
    "            out_score = model(inp_imgs)\n",
    "        grads = tape.gradient(out_score, inp_imgs)\n",
    "        grads = tf.clip_by_value(grads, -GRADIENT_CLIP, GRADIENT_CLIP) #剪裁\n",
    "        inp_imgs += step_size * grads #梯度“上升”算法更新图像\n",
    "        inp_imgs = tf.clip_by_value(inp_imgs, -1.0, 1.0)\n",
    "        if return_img_per_step:\n",
    "            imgs_per_step.append(inp_imgs) \n",
    "    if return_img_per_step:\n",
    "        return tf.stack(imgs_per_step, axis=0) #tf.stack()是拼接函数\n",
    "    else:\n",
    "        return inp_imgs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "180fb0a1-ed16-47c2-b326-ad66071cd6e2",
   "metadata": {},
   "source": [
    "## 3. Set up a buffer to store examples <a name=\"buffer\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52615dcd-be2b-4e05-b729-0ec45ea6ef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Buffer: #P197我们还维护了以前迭代的样本缓冲区，这样我们就可以将其作为下一批的起点，而不是纯随机噪声。\n",
    "    def __init__(self, model):\n",
    "        super().__init__()\n",
    "        self.model = model\n",
    "        self.examples = [ #注意，最终是一个列表，长度=BATCH_SIZE\n",
    "            tf.random.uniform(shape=(1, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)) * 2 - 1 #tf.random.uniform用于从均匀分布中输出随机值，默认0~1之间。\n",
    "            for _ in range(BATCH_SIZE) #见“python列表推导式、列表解析式.pdf”\n",
    "        ]\n",
    "\n",
    "    def sample_new_exmps(self, steps, step_size, noise):\n",
    "        #5%的观察是从零开始(也即随机噪声)\n",
    "        #np.random.binomial(128, 0.5)结果61，np.random.binomial(128, 1)结果128，np.random.binomial(128, 0)结果0，np.random.binomial(128, 0.05)结果6\n",
    "        n_new = np.random.binomial(BATCH_SIZE, 0.05) #二项分布。numpy.random.binomial(n,p,size=None)  一次试验的样本数n。事件发生的概率p，范围[0,1]。返回每次试验事件发生的次数，次数大于等于0且小于等于参数n。\n",
    "        rand_imgs = (tf.random.uniform((n_new, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)) * 2 - 1) #rand_imgs= tf.Tensor(..., shape=(n_new, 32, 32, 1), dtype=float32)\n",
    "        #其余的直接从已有的缓存中随机抽取\n",
    "        old_imgs = tf.concat(\n",
    "            random.choices(self.examples, k=BATCH_SIZE - n_new), axis=0 #random.choices()从一个列表中随机选择多个元素，每个元素可能出现多次。参数是k，表示要随机抽取的元素数量。如果不指定k值，则默认为1。\n",
    "        ) #old_imgs= tf.Tensor(..., shape=(k, 32, 32, 1), dtype=float32)\n",
    "        # 新老样本连接起来并通过Langevin取样器\n",
    "        inp_imgs = tf.concat([rand_imgs, old_imgs], axis=0) #inp_imgs= tf.Tensor(..., shape=(BATCH_SIZE, 32, 32, 1), dtype=float32)\n",
    "        inp_imgs = generate_samples(self.model, inp_imgs, steps=steps, step_size=step_size, noise=noise) #inp_imgs= tf.Tensor(..., shape=(BATCH_SIZE, 32, 32, 1), dtype=float32)\n",
    "        # 结果样本加入buffer，修剪到最长为8192个观察\n",
    "        self.examples = tf.split(inp_imgs, BATCH_SIZE, axis=0) + self.examples #tf.split（）分割张量返回列表。这里两个列表相加=拼接（无任何数学运算，与张量加法运算不同的）。最终是一个列表，长度=2*BATCH_SIZE。注意x+y不等于y+x，这里老的放到后面的\n",
    "        self.examples = self.examples[:BUFFER_SIZE] #[:BUFFER_SIZE]列表切片，从0~8192\n",
    "        return inp_imgs #返回值是<tf.Tensor: shape=(BATCH_SIZE, 32, 32, 1), dtype=float32, numpy=.....>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71a2a4a1-690e-4c94-b323-86f0e5b691d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EBM(models.Model):\n",
    "    def __init__(self):\n",
    "        super(EBM, self).__init__()\n",
    "        self.model = model\n",
    "        self.buffer = Buffer(self.model)\n",
    "        self.alpha = ALPHA\n",
    "        self.loss_metric = metrics.Mean(name=\"loss\")\n",
    "        self.reg_loss_metric = metrics.Mean(name=\"reg\")\n",
    "        self.cdiv_loss_metric = metrics.Mean(name=\"cdiv\")\n",
    "        self.real_out_metric = metrics.Mean(name=\"real\")\n",
    "        self.fake_out_metric = metrics.Mean(name=\"fake\")\n",
    "\n",
    "    @property\n",
    "    def metrics(self):\n",
    "        return [\n",
    "            self.loss_metric,\n",
    "            self.reg_loss_metric,\n",
    "            self.cdiv_loss_metric,\n",
    "            self.real_out_metric,\n",
    "            self.fake_out_metric,\n",
    "        ]\n",
    "\n",
    "    def train_step(self, real_imgs):\n",
    "        real_imgs += tf.random.normal(shape=tf.shape(real_imgs), mean=0, stddev=NOISE) #tf.random.normal正态分布。真实图像添加噪声\n",
    "        real_imgs = tf.clip_by_value(real_imgs, -1.0, 1.0) #剪裁\n",
    "        fake_imgs = self.buffer.sample_new_exmps(steps=STEPS, step_size=STEP_SIZE, noise=NOISE) #从buffer中采样假图\n",
    "        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n",
    "        with tf.GradientTape() as training_tape:\n",
    "            #real_out, fake_out = tf.split(self.model(inp_imgs, training=True), 2, axis=0) #真实图像和虚假图像通过模型生成分数.这里添加“training=True”调用dropout\n",
    "            real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0)\n",
    "            cdiv_loss = tf.reduce_mean(fake_out, axis=0) - tf.reduce_mean(real_out, axis=0) #损失=真实图像和虚假图像的分数之差。\n",
    "            reg_loss = self.alpha * tf.reduce_mean(real_out**2 + fake_out**2, axis=0) #加上正则损失。b = tf.constant([3.0, 4.0]) ;print(b**2)#=print(tf.square(b))#tf.Tensor([ 9. 16.], shape=(2,), dtype=float32)\n",
    "            loss = cdiv_loss + reg_loss\n",
    "        grads = training_tape.gradient(loss, self.model.trainable_variables)\n",
    "        self.optimizer.apply_gradients(zip(grads, self.model.trainable_variables))\n",
    "        self.loss_metric.update_state(loss)\n",
    "        self.reg_loss_metric.update_state(reg_loss)\n",
    "        self.cdiv_loss_metric.update_state(cdiv_loss)\n",
    "        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis=0))\n",
    "        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis=0))\n",
    "        return {m.name: m.result() for m in self.metrics}\n",
    "\n",
    "    def test_step(self, real_imgs): #评估循环：一个简单的for 循环，重复调用test_step() 函数。test_step() 函数只是train_step() 逻辑的子集。它省略了处理更新模型权重的代码，即所有涉及GradientTape 和优化器的代码。见《python深度学习第二版》P170\n",
    "        batch_size = real_imgs.shape[0]\n",
    "        fake_imgs = (\n",
    "            tf.random.uniform((batch_size, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS))\n",
    "            * 2\n",
    "            - 1\n",
    "        )\n",
    "        inp_imgs = tf.concat([real_imgs, fake_imgs], axis=0)\n",
    "        real_out, fake_out = tf.split(self.model(inp_imgs), 2, axis=0)\n",
    "        cdiv = tf.reduce_mean(fake_out, axis=0) - tf.reduce_mean(\n",
    "            real_out, axis=0\n",
    "        )\n",
    "        self.cdiv_loss_metric.update_state(cdiv)\n",
    "        self.real_out_metric.update_state(tf.reduce_mean(real_out, axis=0))\n",
    "        self.fake_out_metric.update_state(tf.reduce_mean(fake_out, axis=0))\n",
    "        return {m.name: m.result() for m in self.metrics[2:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6337e801-eb59-4abe-84dc-9536cf4dc257",
   "metadata": {},
   "outputs": [],
   "source": [
    "ebm = EBM()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b14665-4359-447b-be58-3fd58ba69084",
   "metadata": {},
   "source": [
    "## 3. Train the EBM network <a name=\"train\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ec362d-41fa-473a-ad56-ebeec6cfd3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile and train the model\n",
    "ebm.compile(\n",
    "    optimizer=optimizers.Adam(learning_rate=LEARNING_RATE,\n",
    "                              #clipnorm=1 #自增clipnorm=1。所有参数梯度将被裁剪，让其 l2 范数最大为 1：g * 1 / max(1, l2_norm)\n",
    "                             ), run_eagerly=True \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ceca4de-f634-40ff-beb8-09ba42fd0f75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = callbacks.TensorBoard(log_dir=\"./logs\")\n",
    "\n",
    "\n",
    "class ImageGenerator(callbacks.Callback):\n",
    "    def __init__(self, num_img):\n",
    "        self.num_img = num_img\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        start_imgs = (\n",
    "            np.random.uniform(\n",
    "                size=(self.num_img, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)\n",
    "            )\n",
    "            * 2\n",
    "            - 1\n",
    "        )\n",
    "        generated_images = generate_samples(\n",
    "            ebm.model,\n",
    "            start_imgs,\n",
    "            steps=int(1000*10/STEP_SIZE), #原值1000\n",
    "            step_size=STEP_SIZE,\n",
    "            noise=NOISE,\n",
    "            return_img_per_step=False,\n",
    "        )\n",
    "        generated_images = generated_images.numpy()\n",
    "        display(\n",
    "            generated_images,\n",
    "            n=self.num_img,  #自增\n",
    "            size=(80, 2),   #自增，这种比例清晰度高   \n",
    "            save_to=\"./output/generated_img_%03d.png\" % (epoch),\n",
    "        )\n",
    "\n",
    "        example_images = tf.concat(\n",
    "            random.choices(ebm.buffer.examples, k=10), axis=0\n",
    "        )\n",
    "        example_images = example_images.numpy()\n",
    "        display(\n",
    "            example_images, \n",
    "            n=self.num_img,  #自增\n",
    "            size=(80, 2),   #自增，这种比例清晰度高   \n",
    "            save_to=\"./output/example_img_%03d.png\" % (epoch)\n",
    "        )\n",
    "\n",
    "\n",
    "image_generator_callback = ImageGenerator(num_img=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627c1387-f29a-4cce-85a8-0903c1890e23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SaveModel(callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        model.save_weights(\"./models/model_%03d.h5\" % (epoch)) #每轮均保存\n",
    "\n",
    "\n",
    "save_model_callback = SaveModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd6a5a71-eb55-4ec0-9c8c-cb11a382ff90",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "history=ebm.fit(\n",
    "    x_train,\n",
    "    shuffle=True,\n",
    "    epochs=EPOCHS, \n",
    "    #validation_data=x_test,\n",
    "    callbacks=[\n",
    "        save_model_callback,\n",
    "        tensorboard_callback,\n",
    "        image_generator_callback,\n",
    "    ],\n",
    ")\n",
    "\n",
    "with open('history.history.txt', 'w') as file_object:file_object.write(str(history.history)+'\\n')  #损失写入文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac368976-e2f5-4c0e-8da0-83ca6147c901",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "history_dict = history.history\n",
    "loss = history_dict['loss']\n",
    "reg = history_dict['reg']\n",
    "cdiv = history_dict['cdiv']\n",
    "real = history_dict['real']\n",
    "fake = history_dict['fake']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'b', label='loss')\n",
    "plt.plot(epochs, reg, 'g', label='reg')\n",
    "plt.plot(epochs, cdiv, 'r', label='cdiv')\n",
    "plt.plot(epochs, real, 'c', label='real')\n",
    "plt.plot(epochs, fake, 'y', label='fake')\n",
    "plt.title('Training loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb1f295f-ade0-4040-a6a5-a7b428b08ebc",
   "metadata": {},
   "source": [
    "## 4. Generate images <a name=\"generate\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db3cfe3-339e-463d-8af5-fbd403385fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_imgs = (\n",
    "    np.random.uniform(size=(10, IMAGE_SIZE[0], IMAGE_SIZE[1], CHANNELS)) * 2 - 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80087297-3f47-4e0c-ac89-8758d4386d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(start_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaf4b749-5f6e-4a12-863f-b0bbcd23549c",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "gen_img = generate_samples(\n",
    "    ebm.model,\n",
    "    start_imgs,\n",
    "    steps=int(1000*10/STEP_SIZE), #原值1000\n",
    "    step_size=STEP_SIZE,\n",
    "    noise=NOISE,\n",
    "    return_img_per_step=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac707f6-0597-499c-9a52-7cade6724795",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "display(gen_img[-1].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8476aaa1-e0e7-44dc-a1fd-cc30344b8dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "imgs = []\n",
    "for i in [0, 1, 3, 5, 10, 30, 50, 100, 300, 999]:\n",
    "    imgs.append(gen_img[i].numpy()[6])\n",
    "\n",
    "display(np.array(imgs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11931ce2-b35b-48b8-88fb-6bcd7b4700ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "endTime=time.time()\n",
    "print('How many minutes:',(endTime-startTime)/60)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
